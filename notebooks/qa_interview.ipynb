{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:40px\">Example lesson</font>\n",
    "<p><font style=\"font-size:26px\">Bootstrapping for better sales reports</font></p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#h1_introduction)\n",
    "1. [Workspace setup](#h1_workspace_setup)\n",
    "1. [Load data](#h1_load_data)\n",
    "1. [Data exploration](#h1_data_exploration)\n",
    "1. [Data cleaning](#h1_data_cleaning)\n",
    "1. [Create a basic sales report](#h1_basic_sales_report)\n",
    "1. [Create a better sales report](#h1_better_sales_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<a id='h1_introduction'></a>\n",
    "\n",
    "In this session, we will create a basic sales report for a data set from an online retailer. We will then apply bootstrapping to identify which of the apparent trends are statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "* Use pandas `groupby()`, `agg()` and `apply()` for dataframe aggregation.\n",
    "* Use pandas `apply()` with a custom aggregate function to produce a basic sales report.\n",
    "* Modify our custom aggregate function to produce a bootstrapped sales report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumed prior knowledge\n",
    "Python:\n",
    "* __pandas__: Dataframe interrogation and slicing. Familiarity with `groupby()`, `agg()` and `apply()` beneficial but not necessary.\n",
    "* __numpy__: `np.random.choice()`.\n",
    "* List comprehension.\n",
    "\n",
    "Other:\n",
    "* Some familiarity with the concepts of bootstrapping and Monte Carlo methods. (Perhaps these were introduced in the previous session.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace setup\n",
    "<a id='h1_workspace_setup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a few common commands.\n",
    "%run workspace_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common.\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Charting.\n",
    "import seaborn as sns\n",
    "\n",
    "# Misc.\n",
    "from IPython.display import Image # Display an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `qa_fns` contains a few functions for producing charts and dataframes for this lesson.\n",
    "import functions.qa_fns as qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%aimport functions.qa_fns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "<a id='h1_load_data'></a>\n",
    "`retail_df` is a pandas dataframe containing sales data for an online retailer.\n",
    "\n",
    "The dataframe has been saved in the pickle format instead of the more common CSV. The main advantage of the pickle format is that it faithfully preserves the dataframe object, including column dtypes.\n",
    "\n",
    "Data source: https://www.kaggle.com/mashlyn/online-retail-ii-uci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df = pd.read_pickle(os.path.join('..', 'data', 'retail.pkl'))\n",
    "retail_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column name | Description\n",
    "--- | ---\n",
    "Index: `invoice_id` | Unique order ID. Prefix \"C\" indicates a cancelled order.\n",
    "`invoice_date_dt` | Datetime of order.\n",
    "`period_id` | Year and quarter of order.\n",
    "`country` | Country order placed from.\n",
    "`order_value` | Order value in GBP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "<a id='h1_data_exploration'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reminder of why data exploration is important.\n",
    "# https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02133-w.\n",
    "Image(os.path.join('..', 'images', 'bmi_steps.png'), retina=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick glance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spend a few minutes examining the dataframe, `retail_df`, any way you like.\n",
    "\n",
    "Some functions that might be useful:\n",
    "* `pd.DataFrame.head(n)`\n",
    "* `pd.DataFrame.sample(n)`\n",
    "* `pd.DataFrame.describe()`\n",
    "* `pd.DataFrame.dtypes()`\n",
    "* `set()` or `pd.Series.unique()`\n",
    "* `pd.Series.sum()`; `pd.Series.mean()`\n",
    "* `pd.DataFrame.groupby(...).describe()`\n",
    "* `pd.DataFrame.groupby(...).agg(...)`\n",
    "\n",
    "Example: `retail_df.sample(10)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retail_df['country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df['period_id'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do any of the histograms look \"unusual\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "We will use the pandas dataframe methods `groupby()`, `agg()` and `sort_values()` to compute some aggregate statistics on `retail_df`.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html\n",
    "\n",
    "An example of the syntax is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_invoices_by_country_df = retail_df.groupby([\n",
    "    'country'\n",
    "]).agg(\n",
    "    n_invoices=('order_value', 'count') # Syntax: new_aggregate_column_name=('existing_column_name', 'builtin_function_name' or custom_function_name).\n",
    ").sort_values(\n",
    "    by='n_invoices',\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "n_invoices_by_country_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_invoices_by_country_df.plot.bar(\n",
    "    log=True,\n",
    "    figsize=(15, 6)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Modify the code that generated `n_invoices_by_country_df` to create a new dataframe, `sales_by_country_df`. You will need to use the aggregate function \"sum\" instead of \"count\".\n",
    "\n",
    "Call `plot.bar()` on this new dataframe, as we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_by_country_df = retail_df.groupby([\n",
    "    'country'\n",
    "]).agg(\n",
    "    sales=('order_value', 'sum'),\n",
    ").sort_values(\n",
    "    by='sales',\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "sales_by_country_df.plot.bar(\n",
    "    log=True,\n",
    "    figsize=(15, 6)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "The UK seems to have much higher sales than the other countries.\n",
    "\n",
    "What fraction of all sales value comes from the UK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(retail_df.loc[retail_df['country'] == 'United Kingdom', 'order_value']) / sum(retail_df['order_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter `retail_df` to just the countries with highest sales\n",
    "There are a lot of countries with very low sales. Let's focus on just the top 12 countries for the remainder of the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_selling_countries = sales_by_country_df.index[:12]\n",
    "top_selling_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retail_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df = retail_df.loc[retail_df['country'].isin(top_selling_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retail_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "We will plot a histogram of order value for each country.\n",
    "\n",
    "There is a pandas built-in method, `hist()`, for plotting these histograms with a single command. However, the results are not always visually clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retail_df['order_value'].hist(\n",
    "    by=retail_df['country'],\n",
    "    figsize=(15, 10),\n",
    "    #bins=40\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate better-looking histograms by employing seaborn.\n",
    "\n",
    "A wrapper function, `seaborn_histplot_grid()`, is provided for expedience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.seaborn_histplot_grid(retail_df, value_colname='order_value', groupby_colname='country', groupby_categories=top_selling_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "<a id='h1_data_cleaning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove invoices with value £0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retail_df.loc[retail_df['order_value'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retail_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df = retail_df.loc[retail_df['order_value'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retail_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.seaborn_histplot_grid(retail_df, value_colname='order_value', groupby_colname='country', groupby_categories=top_selling_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a basic sales report\n",
    "<a id='h1_basic_sales_report'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:20px\">Goal</font> \\\n",
    "Compare the total sales in period __Q1_2010__ with the total sales in period __Q1_2011__, country by country.\n",
    "\n",
    "The output should be a dataframe with `country` as the index, and the following columns:\n",
    "* The number of orders in {Q1_2010, Q1_2011}.\n",
    "* The total sales in {Q1_2010, Q1_2011}.\n",
    "* The change in sales (increase or decrease) in £ from Q1_2010 to Q1_2011.\n",
    "* The relative change in sales, expressed as a fraction. E.g. 0.25 means a 25% increase in sales; -0.05 means a 5% decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_id_0, period_id_1 = 'Q1_2010', 'Q1_2011'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom aggregate function for use with `apply`\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.apply.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_apply_fn(df: pd.DataFrame) -> pd.Series:\n",
    "    '''Simple example function for use as follows: `pd.DataFrame.groupby(...).apply(example_apply_fn)`.\n",
    "    To be compatible with `apply()`, a function must take a pandas DataFrame as its first argument and return a DataFrame, Series or scalar.'''\n",
    "    return pd.Series(\n",
    "        {\n",
    "            'sales':      df['order_value'].sum(),\n",
    "            'n_invoices': len(df['order_value'])\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.groupby([   # The `groupby` column(s) become the index of the output dataframe.\n",
    "    'country'\n",
    "]).apply(             # The function specified in `apply` is applied to each of the dataframes returned by `groupby`.\n",
    "    example_apply_fn  # The outputs of this function are stitched together to form the output dataframe.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a `compare_sales()` function\n",
    "\n",
    "Now we will write a new function for use with `apply`. The function must create an output dataframe as specified in the Goal.\n",
    "\n",
    "A reminder of the required columns:\n",
    "* The number of orders in {Q1_2010, Q1_2011}.\n",
    "* The total sales in {Q1_2010, Q1_2011}.\n",
    "* The change in sales (increase or decrease) in £ from Q1_2010 to Q1_2011.\n",
    "* The relative change in sales, expressed as a fraction. E.g. 0.25 means a 25% increase in sales; -0.05 means a 5% decrease.\n",
    "\n",
    "Let's also allow the names of the two periods being compared to be passed as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sales(df: pd.DataFrame, period_id_0: str, period_id_1: str) -> pd.Series:\n",
    "    '''Usage: `retail_df.groupby('country').apply(compare_sales, period_id_0, period_id_1)`.\n",
    "    \n",
    "    Args:\n",
    "        period_id_0 (str): Name of the first period to compare--matching one of the periods from the `period_id` column of `retail_df`. E.g. 'Q1_2011'.\n",
    "        period_id_1 (str): Name of the second period to compare. E.g. 'Q1_2010'.\n",
    "    '''\n",
    "    df_p0 = df.loc[df['period_id'] == period_id_0]\n",
    "    df_p1 = df.loc[df['period_id'] == period_id_1]\n",
    "    \n",
    "    return pd.Series(\n",
    "        {\n",
    "            f'n_orders_{period_id_0}':  len(df_p0),\n",
    "            f'n_orders_{period_id_1}':  len(df_p1),\n",
    "            f'sales_{period_id_0}':     ...,\n",
    "            f'sales_{period_id_1}':     ...,\n",
    "            'Δ_sales':                  ... - ...,\n",
    "            'rel_change_sales':         ... / ... - 1\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sales(df: pd.DataFrame, period_id_0: str, period_id_1: str) -> pd.Series:\n",
    "    '''Usage: `retail_df.groupby('country').apply(compare_sales, period_id_0, period_id_1)`.\n",
    "    \n",
    "    Args:\n",
    "        period_id_0 (str): Name of the first period to compare--matching one of the periods from the `period_id` column of `retail_df`. E.g. 'Q1_2011'.\n",
    "        period_id_1 (str): Name of the second period to compare. E.g. 'Q1_2010'.\n",
    "    '''\n",
    "    df_p0 = df.loc[df['period_id'] == period_id_0]\n",
    "    df_p1 = df.loc[df['period_id'] == period_id_1]\n",
    "    \n",
    "    p0_sales_sum = df_p0['order_value'].sum()\n",
    "    p1_sales_sum = df_p1['order_value'].sum()\n",
    "    \n",
    "    return pd.Series(\n",
    "        {\n",
    "            f'n_orders_{period_id_0}':  len(df_p0),\n",
    "            f'n_orders_{period_id_1}':  len(df_p1),\n",
    "            f'sales_{period_id_0}':     p0_sales_sum,\n",
    "            f'sales_{period_id_1}':     p1_sales_sum,\n",
    "            'Δ_sales':                  p1_sales_sum - p0_sales_sum,\n",
    "            'rel_change_sales':         p1_sales_sum / p0_sales_sum - 1\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales_by_country = retail_df.loc[\n",
    "#     retail_df['period_id'].isin([period_id_0, period_id_1])\n",
    "\n",
    "sales_by_country = retail_df.groupby([\n",
    "    'country'\n",
    "]).apply(                     # Note the syntax: arguments to our `compare_sales()` function must be passed as keyword arguments (`kwargs`) to `apply()`.\n",
    "    compare_sales,\n",
    "    period_id_0=period_id_0,\n",
    "    period_id_1=period_id_1\n",
    ").reindex(                    # An optional step: order the output dataframe by `top_selling_countries`.\n",
    "    top_selling_countries\n",
    ")\n",
    "\n",
    "sales_by_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the readability of the sales dataframe\n",
    "The function `sales_dataframe_styler()` is provided to improve the readability of the sales summary dataframes generated during this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.sales_dataframe_styler(sales_by_country, period_id_0, period_id_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our basic sales report is now complete.\n",
    "\n",
    "Questions:\n",
    "* Does this table tell the whole story?\n",
    "* What important information is missing (if any)?\n",
    "* How can we improve this sales report?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a better sales report\n",
    "<a id='h1_better_sales_report'></a>\n",
    "\n",
    "> “It is easy to lie with statistics. It is hard to tell the truth without statistics.”\n",
    ">\n",
    "> — Andrejs Dunkels\n",
    "\n",
    "The basic sales report dataframe provides some standard metrics of sales performance. However, these figures lack any measure of statistical significance.\n",
    "\n",
    "It would be much better if the sales report gave us a __confidence interval__ around each of the figures of interest. These confidence intervals can be estimated via __bootstrapping__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping: a quick reminder\n",
    "Bootstrapping is a method of sampling with replacement from a data set in order to generate a new, unbiased sample from approximately the same distribution that generated the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(np.random.choice(range(10), size=10, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sales_bootstrapped(df: pd.DataFrame, period_id_0: str, period_id_1: str, n_boot: int=5000) -> pd.Series:\n",
    "    '''An upgraded version of `compare_sales` which adds bootstrapped sales metrics. Bootstrapped columns have the prefix \"bs_\".'''\n",
    "    df_p0 = df.loc[df['period_id'] == period_id_0]\n",
    "    df_p1 = df.loc[df['period_id'] == period_id_1]\n",
    "    \n",
    "    p1_minus_p0 = []\n",
    "    p1_div_p0 = []\n",
    "    \n",
    "    # Bootstrap loop.\n",
    "    for i in range(n_boot):\n",
    "        # Draw a bootstrap sample of order value for Period 0 and take the sum. Do the same for Period 1.\n",
    "        bs_p0_sales = np.sum(np.random.choice(df_p0['order_value'], size=len(df_p0), replace=True))\n",
    "        bs_p1_sales = np.sum(np.random.choice(df_p1['order_value'], size=len(df_p1), replace=True))\n",
    "        \n",
    "        # Append the difference of the bootstrapped sales values to list `p1_minus_p0`, and their quotient to `p1_div_p0`.\n",
    "        p1_minus_p0.append(bs_p1_sales - bs_p0_sales)\n",
    "        p1_div_p0.append(bs_p1_sales / bs_p0_sales)\n",
    "    \n",
    "    # Compute the unbootstrapped (i.e. actual) sales for each Period.\n",
    "    p0_sales = df_p0['order_value'].sum()\n",
    "    p1_sales = df_p1['order_value'].sum()\n",
    "    \n",
    "    # Compute the percentiles for the bootstrapped £ change and relative change in sales between Period 0 and Period 1.\n",
    "    Δ_percentiles = np.quantile(p1_minus_p0, [0.025, 0.5, 0.975])\n",
    "    rel_change_percentiles = np.quantile(p1_div_p0, [0.025, 0.5, 0.975])\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            f'n_orders_{period_id_0}':     len(df_p0),                       # Number of orders for Period 0.\n",
    "            f'n_orders_{period_id_1}':     len(df_p1),                       # Number of orders for Period 1.\n",
    "            f'sales_{period_id_0}':        p0_sales,                         # Unbootstrapped (i.e. actual) sales for Period 0.\n",
    "            f'sales_{period_id_1}':        p1_sales,                         # Unbootstrapped (i.e. actual) sales for Period 1.\n",
    "            'Δ_sales':                     p1_sales - p0_sales,              # £ difference/change in sales between Period 0 and Period 1.\n",
    "            'rel_change_sales':            p1_sales / p0_sales - 1,          # Relative change in sales between Period 0 and Period 1. E.g. 0.25 means a +25% change.\n",
    "            'bs_Δ_sales_mean':             np.nanmean(p1_minus_p0),          # Mean of bootstraps of £ change in sales between Period 0 and Period 1.\n",
    "            'bs_Δ_sales_sd':               np.nanstd(p1_minus_p0),           # Standard deviation of bootstraps of £ change in sales between Period 0 and Period 1.\n",
    "            'bs_Δ_sales_q0.025':           Δ_percentiles[0],                 # 2.5th percentile of bootstraps of £ change in sales between Period 0 and Period 1.\n",
    "            'bs_Δ_sales_q0.5':             Δ_percentiles[1],                 # 50th percentile (i.e. median) of bootstraps of £ change in sales between Period 0 and Period 1.\n",
    "            'bs_Δ_sales_q0.975':           Δ_percentiles[2],                 # 97.5th percentile of bootstraps of £ change in sales between Period 0 and Period 1.\n",
    "            'bs_rel_change_sales_mean':    np.nanmean(p1_div_p0),            # Mean of bootstraps of relative change in sales between Period 0 and Period 1.\n",
    "            'bs_rel_change_sales_sd':      np.nanstd(p1_div_p0),             # Standard deviation of bootstraps of relative change in sales between Period 0 and Period 1.\n",
    "            'bs_rel_change_sales_q0.025':  rel_change_percentiles[0] - 1,    # 2.5th percentile of bootstraps of relative change in sales between Period 0 and Period 1.\n",
    "            'bs_rel_change_sales_q0.5':    rel_change_percentiles[1] - 1,    # 50th percentile of bootstraps of relative change in sales between Period 0 and Period 1.\n",
    "            'bs_rel_change_sales_q0.975':  rel_change_percentiles[2] - 1,    # 97.5th percentile of bootstraps of relative change in sales between Period 0 and Period 1.\n",
    "            f'{period_id_1}_>_{period_id_0}_frac': np.mean(                  # The fraction of bootstraps in which the sales in Period 1 exceeded those in Period 0.\n",
    "                [quotient >= 1 for quotient in p1_div_p0]\n",
    "            )\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ~ 16 s for n_boot == 20,000.\n",
    "bs_sales_by_country = retail_df.groupby(\n",
    "    ['country']\n",
    ").apply(\n",
    "    compare_sales_bootstrapped,\n",
    "    period_id_0=period_id_0,\n",
    "    period_id_1=period_id_1,\n",
    "    n_boot=20000\n",
    ").reindex(\n",
    "    top_selling_countries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.sales_dataframe_styler(bs_sales_by_country, period_id_0, period_id_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.sales_dataframe_styler(\n",
    "    bs_sales_by_country[[colname for colname in bs_sales_by_country.columns if ('Δ' in colname) or ('n_orders' in colname)] + [bs_sales_by_country.columns[-1]]],\n",
    "    period_id_0,\n",
    "    period_id_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.sales_dataframe_styler(\n",
    "    bs_sales_by_country[[colname for colname in bs_sales_by_country.columns if ('rel_change' in colname) or ('n_orders' in colname)] + [bs_sales_by_country.columns[-1]]].drop(columns=['bs_rel_change_sales_mean', 'bs_rel_change_sales_sd']),\n",
    "    period_id_0,\n",
    "    period_id_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> “Offered the choice between mastery of a five-foot shelf of analytical statistics books and middling ability at performing statistical Monte Carlo simulations, we would surely choose to have the latter skill.”\n",
    ">\n",
    "> _— Numerical Recipes: The Art of Scientific Computing_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (QA interview)",
   "language": "python",
   "name": "qa_interview_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
